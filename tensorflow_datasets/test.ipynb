{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from medpy.io import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset brats2015/0.1.0 (download: Unknown size, generated: Unknown size, total: Unknown size) to /Users/Jingjing/tensorflow_datasets/brats2015/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a0cc669de84772ad9c498c5f9de1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dtype uint8 do not match int16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6d172ab8aac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Brats2015'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    377\u001b[0m           self._download_and_prepare(\n\u001b[1;32m    378\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m               download_config=download_config)\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m           \u001b[0;31m# NOTE: If modifying the lines below to put additional information in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     super(GeneratorBasedBuilder, self)._download_and_prepare(\n\u001b[1;32m   1032\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m     )\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;31m# Update the info object with the splits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[0;34m(self, split_generator, max_examples_per_split)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     for key, record in utils.tqdm(generator, unit=\" examples\",\n\u001b[1;32m   1048\u001b[0m                                   total=split_info.num_examples, leave=False):\n\u001b[0;32m-> 1049\u001b[0;31m       \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m       \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0mshard_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/features/features_dict.py\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(self, example_dict)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     }\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/features/features_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m     return {\n\u001b[1;32m    193\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     }\n",
      "\u001b[0;32m/Users/Jingjing/opt/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/features/feature.py\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(self, example_data)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       raise ValueError('Dtype {} do not match {}'.format(\n\u001b[0;32m--> 674\u001b[0;31m           example_data.dtype, np_dtype))\n\u001b[0m\u001b[1;32m    675\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexample_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dtype uint8 do not match int16"
     ]
    }
   ],
   "source": [
    "tfds.load('Brats2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "# TODO(brats_2015): BibTeX citation\n",
    "_CITATION = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# TODO(brats_2015):\n",
    "_DESCRIPTION = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Brats2015(tfds.core.GeneratorBasedBuilder):\n",
    "  \"\"\"TODO(brats_2015): Short description of my dataset.\"\"\"\n",
    "\n",
    "  # TODO(brats_2015): Set up version.\n",
    "  VERSION = tfds.core.Version('0.1.0')\n",
    "\n",
    "  def _info(self):\n",
    "    # TODO(brats_2015): Specifies the tfds.core.DatasetInfo object\n",
    "    return tfds.core.DatasetInfo(\n",
    "        builder=self,\n",
    "        # This is the description that will appear on the datasets page.\n",
    "        description=_DESCRIPTION,\n",
    "        # tfds.features.FeatureConnectors\n",
    "        features=tfds.features.FeaturesDict({\n",
    "        ## Tumor Type\n",
    "        'type' : tfds.features.Text(),\n",
    "        ## Modality\n",
    "        'modality': tfds.features.Text(),\n",
    "        #The MRI image\n",
    "        'image' : tfds.features.Tensor(shape=(240,240),dtype=tf.int16),\n",
    "        ## The mask\n",
    "        'mask' : tfds.features.Tensor(shape=(240,240),dtype = tf.int8),\n",
    "        \n",
    "        }),\n",
    "        # If there's a common (input, target) tuple from the features,\n",
    "        # specify them here. They'll be used if as_supervised=True in\n",
    "        # builder.as_dataset.\n",
    "        supervised_keys=('image','mask'),\n",
    "        # Homepage of the dataset for documentation\n",
    "        homepage='https://dataset-homepage/',\n",
    "        citation=_CITATION,\n",
    "    )\n",
    "\n",
    "  def _split_generators(self, dl_manager):\n",
    "    \"\"\"Returns SplitGenerators.\"\"\"\n",
    "    # TODO(brats_2015): Downloads the data and defines the splits\n",
    "    # dl_manager is a tfds.download.DownloadManager that can be used to\n",
    "    # download and extract URLs\n",
    "    if not tf.io.gfile.exists(dl_manager.manual_dir):\n",
    "        msg = \"You must download the dataset files manually and place them in: \"\n",
    "        msg += dl_manager.manual_dir\n",
    "        raise AssertionError(msg)\n",
    "        \n",
    "    # There is no predefined train/val/test split for this dataset\n",
    "    return [\n",
    "        tfds.core.SplitGenerator(\n",
    "            name=tfds.Split.TRAIN,\n",
    "            gen_kwargs={\n",
    "                \"filepath\": dl_manager.manual_dir\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "  def _generate_examples(self,filepath=None):\n",
    "    \"\"\"Yields examples.\"\"\"\n",
    "    # TODO(brats_2015): Yields (key, example) tuples from the dataset\n",
    "    yield 'key', {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Brats2015()\n",
    "test._split_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath ='/Users/Jingjing/tensorflow_datasets/downloads/manual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Jingjing/tensorflow_datasets/downloads/manual/BRATS2015_Training'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brats = filepath +'/BRATS2015_Training'\n",
    "brats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tumor_type in tf.io.gfile.listdir(brats):\n",
    "    if tumor_type.startswith('.'):\n",
    "        pass\n",
    "    else:\n",
    "        tumor_type_path = os.path.join(brats,tumor_type)\n",
    "        for pat in tf.io.gfile.listdir(tumor_type_path):\n",
    "            if pat.startswith('.'):\n",
    "                pass\n",
    "            else:\n",
    "                pat_path = os.path.join(tumor_type_path,pat)\n",
    "                image_files = []\n",
    "                for file in tf.io.gfile.listdir(pat_path):\n",
    "\n",
    "                    if 'OT.' in file:\n",
    "                        for image in tf.io.gfile.listdir(os.path.join(pat_path,file)):\n",
    "                            if image.endswith('.mha'):\n",
    "                                mask_file = os.path.join(pat_path,file,image)\n",
    "                                break\n",
    "\n",
    "                    else:\n",
    "                        for image in tf.io.gfile.listdir(os.path.join(pat_path,file)):\n",
    "                            if image.endswith('.mha'):\n",
    "                                image_files.append(os.path.join(pat_path,file,image))\n",
    "                mask_array,mask_header = load(mask_file)\n",
    "                total_slices = mask_array.shape[2]\n",
    "                for image in image_files:\n",
    "                    modality = image.split('/')[-1].split('.')[-3].split('_')[-1]\n",
    "                    image_array, image_header = load(image)\n",
    "                    for current_slice in range(0,total_slices):\n",
    "                        key = image.split('/')[-1].split('.')[-2]+'_'+modality+'_'+str(current_slice+1)\n",
    "                        yield( key,\n",
    "                                        {\n",
    "                                                \n",
    "                                                'type' : tumor_type,\n",
    "                                                'modality': modality,\n",
    "                                                'image':image_array[:,:,current_slice],\n",
    "                                                'mask' : mask_array[:,:,current_slice],\n",
    "\n",
    "                                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_array,mask_header = load(mask_file)\n",
    "total_slices = mask_array.shape[2]\n",
    "for image in image_files:\n",
    "                modality = image.split('/')[-1].split('.')[-3].split('_')[-1]\n",
    "                image_array, image_header = load(image)\n",
    "                for current_slice in range(0,total_slices):\n",
    "                    print(image.split('/')[-1].split('.')[-2]+'_'+modality+'_'+str(current_slice+1))\n",
    "                    print('image',image_array[:,:,current_slice].shape)\n",
    "                    print('mask',mask_array[:,:,current_slice].shape)\n",
    "                    print(modality)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tumor_type in tf.io.gfile.listdir(brats):\n",
    "    if tumor_type.startswith('.'):\n",
    "        pass\n",
    "    else:\n",
    "        tumor_type_path = os.path.join(brats,tumor_type)\n",
    "        for pat in tf.io.gfile.listdir(tumor_type_path):\n",
    "            if pat.startswith('.'):\n",
    "                pass\n",
    "            else:\n",
    "                pat_path = os.path.join(tumor_type_path,pat)\n",
    "                image_files = []\n",
    "                for file in tf.io.gfile.listdir(pat_path):\n",
    "                    if file.startswith('.'):\n",
    "                        pass\n",
    "                    else:\n",
    "                        if 'OT.' in file:\n",
    "                            for image in tf.io.gfile.listdir(os.path.join(pat_path,file)):\n",
    "                                if image.endswith('.mha'):\n",
    "                                    mask_file = os.path.join(pat_path,file,image)\n",
    "                                    break\n",
    "\n",
    "                        else:\n",
    "                            for image in tf.io.gfile.listdir(os.path.join(pat_path,file)):\n",
    "                                if image.endswith('.mha'):\n",
    "                                    image_files.append(os.path.join(pat_path,file,image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Jingjing/tensorflow_datasets/downloads/manual/BRATS2015_Training/LGG/brats_tcia_pat261_0001/VSD.Brain_3more.XX.O.OT.42485/VSD.Brain_3more.XX.O.OT.42485.mha'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_array,mask_header = load(mask_file)\n",
    "mask_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
